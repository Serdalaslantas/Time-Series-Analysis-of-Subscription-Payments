# -*- coding: utf-8 -*-
"""subscription_payments.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V5vZ1-AetECyH0C_ZkUga4GVpWRxsex_
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# develop a time series arima forecasting model
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error

import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv('subscription_payments_by_date.csv', sep=';', parse_dates=['date'])
df['total_amount'] = df['total_amount'].astype(float)
print(df.dtypes)
print(df.head())

"""## ARIMA"""

df_ar = pd.read_csv('subscription_payments_by_date.csv', sep=';', parse_dates=['date'],header=0, index_col=0)
# df_ar['total_amount'] = df_ar['total_amount'].diff()
df_ar.head()

df_ar.shape

df_ar.dtypes

df_ar.plot()
plt.show()

# data analysis
# time series decomposition
from statsmodels.tsa.seasonal import seasonal_decompose
result = seasonal_decompose(df_ar['total_amount'], period=30)
result.plot()
plt.show()

from pandas.plotting import autocorrelation_plot
autocorrelation_plot(df_ar)
plt.show()

# fit model
model = ARIMA(df_ar, order=(6,2,0))
model_fit = model.fit()
# summary of fit model
print(model_fit.summary())
# line plot of residuals
residuals = pd.DataFrame(model_fit.resid)
residuals.plot()
plt.show()
# density plot of residuals
residuals.plot(kind='kde')
plt.show()
# summary stats of residuals
print(residuals.describe())

# split into train and test sets
X = df_ar.values
size = int(len(X) * 0.7)
train, test = X[0:size], X[size:len(X)]
history = [x for x in train]
predictions = list()
# walk-forward validation
for t in range(len(test)):
 model = ARIMA(history, order=(6,1,1))
 model_fit = model.fit()
 output = model_fit.forecast()
 yhat = output[0]
 predictions.append(yhat)
 obs = test[t]
 history.append(obs)
 print('predicted=%f, expected=%f' % (yhat, obs))
# evaluate forecasts
rmse = np.sqrt(mean_squared_error(test, predictions))
print('Test RMSE: %.3f' % rmse)
# plot forecasts against actual outcomes
plt.plot(test)
plt.plot(predictions, color='red')
plt.show()

# evaluate an ARIMA model for a given order (p,d,q)
def evaluate_arima_model(X, arima_order):
	# prepare training dataset
	train_size = int(len(X) * 0.7)
	train, test = X[0:train_size], X[train_size:]
	history = [x for x in train]
	# make predictions
	predictions = list()
	for t in range(len(test)):
		model = ARIMA(history, order=arima_order)
		model_fit = model.fit()
		yhat = model_fit.forecast()[0]
		predictions.append(yhat)
		history.append(test[t])
	# calculate out of sample error
	error = mean_squared_error(test, predictions)
	return error

# evaluate combinations of p, d and q values for an ARIMA model
def evaluate_models(dataset, p_values, d_values, q_values):
	dataset = dataset.astype('float32')
	best_score, best_cfg = float("inf"), None
	for p in p_values:
		for d in d_values:
			for q in q_values:
				order = (p,d,q)
				try:
					mse = evaluate_arima_model(dataset, order)
					if mse < best_score:
						best_score, best_cfg = mse, order
					print('ARIMA%s MSE=%.3f' % (order,mse))
				except:
					continue
	print('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))

# evaluate parameters
p_values = [2, 4, 5, 6]
d_values = range(0, 2)
q_values = range(0, 2)
warnings.filterwarnings("ignore")
evaluate_models(df_ar.values, p_values, d_values, q_values)

"""## PROPHET"""

import pandas as pd
from fbprophet import Prophet
from sklearn.metrics import mean_squared_error, mean_absolute_error
from math import sqrt

# Assuming df is your DataFrame and it has columns 'date' and 'total_amount'
df = df.rename(columns={'date': 'ds', 'total_amount': 'y'})

# Initialize and fit the model
model = Prophet()
model.fit(df)

# Make predictions for the next 30 days
future = model.make_future_dataframe(periods=30)
forecast = model.predict(future)

# Calculate metrics
actual = df['y']
predicted = forecast['yhat'][:len(df)]
mse = mean_squared_error(actual, predicted)
rmse = sqrt(mse)
mae = mean_absolute_error(actual, predicted)

print(f'MSE: {mse}')
print(f'RMSE: {rmse}')
print(f'MAE: {mae}')

from prophet import Prophet
df_pr = df.rename(columns={'date': 'ds', 'total_amount': 'y'})
model = Prophet()
model.fit(df_pr)

# predict for next 30 days
future = model.make_future_dataframe(periods=365)
forecast = model.predict(future)
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(30)

# plot forecast
fig1 = model.plot(forecast)
plt.show()

# plot forecast components
fig2 = model.plot_components(forecast)
plt.show()

# Calculate metrics
actual = df_pr['y']
predicted = forecast['yhat'][:len(df_pr)]
mse = mean_squared_error(actual, predicted)
rmse = sqrt(mse)
mae = mean_absolute_error(actual, predicted)

print(f'MAE: {mae}')
print(f'MSE: {mse}')
print(f'RMSE: {rmse}')

#model evulation
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from math import sqrt
mae = mean_absolute_error(test, predictions)
print('MAE: %f' % mae)
mse = mean_squared_error(test, predictions)
print('MSE: %f' % mse)
rmse = sqrt(mse)
print('RMSE: %f' % rmse)

"""## SARIMA"""

from statsmodels.tsa.statespace.sarimax import SARIMAX

df['total_amount_diff'] = df['total_amount'].diff()
df = df.dropna()

model = SARIMAX(df['total_amount_diff'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
model_fit = model.fit()

# Forecast for next 30 days
forecast = model_fit.forecast(30)

ae = mean_absolute_error(test, predictions)
print('MAE: %f' % mae)
mse = mean_squared_error(test, predictions)
print('MSE: %f' % mse)
rmse = sqrt(mse)
print('RMSE: %f' % rmse)

forecast = pd.DataFrame(forecast, columns=['total_amount_diff'])
forecast['total_amount'] = df['total_amount'].iloc[-1] + forecast['total_amount_diff'].cumsum()
forecast = forecast.drop('total_amount_diff', axis=1)
forecast = forecast.reset_index()
forecast = forecast.rename(columns={'index': 'ds'})
forecast['ds'] = forecast['ds'].apply(lambda x: x.date())

#plot forecast
plt.plot(df['date'], df['total_amount'], label='Historical')
plt.plot(forecast['ds'], forecast['total_amount'], label='Forecast')
plt.legend()
plt.show()

"""LSTM and GRU"""

import pandas as pd
from keras.models import Sequential
from keras.layers import Dense, LSTM, GRU
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from math import sqrt
import matplotlib.pyplot as plt
import numpy as np

# Assuming df is your DataFrame and it has columns 'date' and 'total_amount'
df['date'] = pd.to_datetime(df['date'])
df = df.set_index('date')

# Scale the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df)

# Split into train and test sets
train_size = int(len(scaled_data) * 0.7)
test_size = len(scaled_data) - train_size
train, test = scaled_data[0:train_size,:], scaled_data[train_size:len(scaled_data),:]

# Convert an array of values into a dataset matrix
def create_dataset(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        X.append(a)
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)

look_back = 1
X_train, Y_train = create_dataset(train, look_back)
X_test, Y_test = create_dataset(test, look_back)

# Reshape input to be [samples, time steps, features]
X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))
X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))

# Create and fit the LSTM network
model = Sequential()
model.add(LSTM(4, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(X_train, Y_train, epochs=10, batch_size=1, verbose=2)

# Make predictions
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Scale the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df['total_amount'].values.reshape(-1,1))

# Rest of the code remains the same...

# Invert predictions
train_predict = scaler.inverse_transform(train_predict)
Y_train = scaler.inverse_transform(Y_train.reshape(-1,1))
test_predict = scaler.inverse_transform(test_predict)
Y_test = scaler.inverse_transform(Y_test.reshape(-1,1))

# Calculate metrics
train_mse = mean_squared_error(Y_train.flatten(), train_predict[:,0])
test_mse = mean_squared_error(Y_test.flatten(), test_predict[:,0])

print(f'Train MSE: {train_mse}')
print(f'Test MSE: {test_mse}')
print(f'Train RMSE: {sqrt(train_mse)}')
print(f'Test RMSE: {sqrt(test_mse)}')
print(f'Train MAE: {mean_absolute_error(Y_train.flatten(), train_predict[:,0])}')
print(f'Test MAE: {mean_absolute_error(Y_test.flatten(), test_predict[:,0])}')

# Plot baseline and predictions
plt.figure(figsize=(20,10))
plt.plot(scaler.inverse_transform(scaled_data))
plt.plot(train_predict)
plt.plot(np.append(np.empty_like(train_predict), test_predict))
plt.show()